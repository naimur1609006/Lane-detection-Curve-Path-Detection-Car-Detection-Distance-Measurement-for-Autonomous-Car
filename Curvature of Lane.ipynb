{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from moviepy.editor import VideoFileClip\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJTglIayTfiQ",
        "outputId": "aadfba63-9745-4f2a-c65c-c66693e6eb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from moviepy.editor import VideoFileClip\n",
        "from IPython.display import HTML\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install YOLOv5 if not already installed\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install_yolov5():\n",
        "    \"\"\"Install YOLOv5 dependencies\"\"\"\n",
        "    try:\n",
        "        # Try to install ultralytics first (more reliable)\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ultralytics\", \"-q\"])\n",
        "        print(\"Ultralytics installed successfully\")\n",
        "    except:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"yolov5\", \"-q\"])\n",
        "            print(\"YOLOv5 installed successfully\")\n",
        "        except:\n",
        "            print(\"Failed to install YOLOv5 packages\")\n",
        "\n",
        "    try:\n",
        "        # Try custom model first\n",
        "        if os.path.exists('best.pt'):\n",
        "            print(\"Loading custom YOLOv5 model...\")\n",
        "            model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True, trust_repo=True)\n",
        "        else:\n",
        "            print(\"Custom model not found, using YOLOv5s pretrained...\")\n",
        "            model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, trust_repo=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from hub: {e}\")\n",
        "        print(\"Trying alternative approach...\")\n",
        "        try:\n",
        "            # Alternative: use ultralytics YOLO\n",
        "            from ultralytics import YOLO\n",
        "            model = YOLO('yolov5s.pt')\n",
        "            print(\"Loaded YOLOv5s using ultralytics\")\n",
        "        except:\n",
        "            print(\"Failed to load any YOLO model, using dummy detector\")\n",
        "            return None\n",
        "\n",
        "    # Set device\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    if model is not None:\n",
        "        try:\n",
        "            model.to(device)\n",
        "        except:\n",
        "            pass\n",
        "        print(f\"YOLOv5 loaded on {device}\")\n",
        "    return model\n",
        "\n",
        "# Initialize YOLOv5\n",
        "print(\"Initializing YOLOv5...\")\n",
        "yolo_model = install_yolov5()\n",
        "\n",
        "# Configure YOLOv5 for better performance\n",
        "if yolo_model is not None:\n",
        "    try:\n",
        "        yolo_model.conf = 0.25  # Lower confidence threshold for better detection\n",
        "        yolo_model.iou = 0.45   # IoU threshold for NMS\n",
        "        # Include more vehicle classes\n",
        "        yolo_model.classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]  # person, bicycle, car, motorcycle, airplane, bus, train, truck, boat\n",
        "    except:\n",
        "        print(\"Using default YOLO settings\")\n",
        "\n",
        "# Step 1: Camera calibration and undistortion\n",
        "def undistort_img():\n",
        "    \"\"\"Camera calibration function\"\"\"\n",
        "    objp = np.zeros((6*9, 3), dtype=np.float32)\n",
        "    objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
        "\n",
        "    objpoints = []\n",
        "    imgpoints = []\n",
        "\n",
        "    # Create camera_cal directory if it doesn't exist\n",
        "    os.makedirs('camera_cal', exist_ok=True)\n",
        "\n",
        "    images = glob.glob('camera_cal/*.jpg')\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(\"No calibration images found. Creating dummy calibration...\")\n",
        "        # Create dummy calibration parameters for demo\n",
        "        img_size = (1280, 720)\n",
        "        mtx = np.array([[1.15777930e+03, 0.00000000e+00, 6.67111054e+02],\n",
        "                       [0.00000000e+00, 1.15282291e+03, 3.86128938e+02],\n",
        "                       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
        "        dist = np.array([[-2.42565104e-01, -4.77893070e-02, -1.31388084e-03, -8.79107779e-05, 2.20573263e-02]])\n",
        "\n",
        "        dist_pickle = {'mtx': mtx, 'dist': dist}\n",
        "        pickle.dump(dist_pickle, open('camera_cal/cal_pickle.p', 'wb'))\n",
        "        print(\"Dummy calibration created successfully\")\n",
        "        return\n",
        "\n",
        "    for fname in images:\n",
        "        img = cv2.imread(fname)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
        "\n",
        "        if ret:\n",
        "            objpoints.append(objp.copy())\n",
        "            imgpoints.append(corners)\n",
        "\n",
        "    if len(objpoints) > 0:\n",
        "        img_size = (img.shape[1], img.shape[0])\n",
        "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
        "\n",
        "        dist_pickle = {'mtx': mtx, 'dist': dist}\n",
        "        pickle.dump(dist_pickle, open('camera_cal/cal_pickle.p', 'wb'))\n",
        "        print(\"Camera calibration successful:\", ret)\n",
        "    else:\n",
        "        print(\"No valid calibration images found\")\n",
        "\n",
        "def undistort(img, cal_dir='camera_cal/cal_pickle.p'):\n",
        "    \"\"\"Undistort image using calibration parameters\"\"\"\n",
        "    try:\n",
        "        with open(cal_dir, 'rb') as f:\n",
        "            calib = pickle.load(f)\n",
        "        mtx = calib['mtx']\n",
        "        dist = calib['dist']\n",
        "        return cv2.undistort(img, mtx, dist, None, mtx)\n",
        "    except:\n",
        "        return img  # Return original if calibration fails\n",
        "\n",
        "# Step 2: Enhanced image processing pipeline\n",
        "def pipeline(img, s_thresh=(100, 255), sx_thresh=(15, 255)):\n",
        "    \"\"\"Enhanced image processing pipeline with better filtering\"\"\"\n",
        "    img = undistort(img)\n",
        "    img = np.copy(img)\n",
        "\n",
        "    # Convert to HLS color space\n",
        "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(float)\n",
        "    h_channel = hls[:, :, 0]\n",
        "    l_channel = hls[:, :, 1]\n",
        "    s_channel = hls[:, :, 2]\n",
        "\n",
        "    # Enhanced yellow line detection\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Yellow mask\n",
        "    yellow_lower = np.array([15, 100, 120])\n",
        "    yellow_upper = np.array([35, 255, 255])\n",
        "    yellow_mask = cv2.inRange(hsv, yellow_lower, yellow_upper)\n",
        "\n",
        "    # White mask\n",
        "    white_lower = np.array([0, 0, 200])\n",
        "    white_upper = np.array([255, 30, 255])\n",
        "    white_mask = cv2.inRange(hsv, white_lower, white_upper)\n",
        "\n",
        "    # Sobel x gradient\n",
        "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0, ksize=7)\n",
        "    abs_sobelx = np.absolute(sobelx)\n",
        "    scaled_sobel = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))\n",
        "\n",
        "    sxbinary = np.zeros_like(scaled_sobel)\n",
        "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
        "\n",
        "    # S channel threshold\n",
        "    s_binary = np.zeros_like(s_channel)\n",
        "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
        "\n",
        "    # Combine all thresholds\n",
        "    combined_binary = np.zeros_like(sxbinary)\n",
        "    combined_binary[(s_binary == 1) | (sxbinary == 1) | (yellow_mask == 255) | (white_mask == 255)] = 1\n",
        "\n",
        "    return combined_binary\n",
        "\n",
        "# Step 3: Perspective transformation\n",
        "def perspective_warp(img,\n",
        "                    dst_size=(1280, 720),\n",
        "                    src=np.float32([(0.43, 0.65), (0.58, 0.65), (0.1, 1), (1, 1)]),\n",
        "                    dst=np.float32([(0, 0), (1, 0), (0, 1), (1, 1)])):\n",
        "    img_size = np.float32([(img.shape[1], img.shape[0])])\n",
        "    src = src * img_size\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    warped = cv2.warpPerspective(img, M, dst_size)\n",
        "    return warped\n",
        "\n",
        "def inv_perspective_warp(img,\n",
        "                         dst_size=(1280, 720),\n",
        "                         src=np.float32([(0, 0), (1, 0), (0, 1), (1, 1)]),\n",
        "                         dst=np.float32([(0.43, 0.65), (0.58, 0.65), (0.1, 1), (1, 1)])):\n",
        "    img_size = np.float32([(img.shape[1], img.shape[0])])\n",
        "    src = src * img_size\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    warped = cv2.warpPerspective(img, M, dst_size)\n",
        "    return warped\n",
        "\n",
        "# Global variables for lane tracking\n",
        "left_a, left_b, left_c = [], [], []\n",
        "right_a, right_b, right_c = [], [], []\n",
        "\n",
        "# Step 4: Enhanced Vehicle detection with multiple approaches\n",
        "def detect_vehicles(img):\n",
        "    \"\"\"Detect vehicles using YOLOv5 with multiple fallback approaches\"\"\"\n",
        "    vehicles = []\n",
        "\n",
        "    if yolo_model is None:\n",
        "        return vehicles\n",
        "\n",
        "    try:\n",
        "        # Method 1: Try ultralytics YOLO approach\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "            if hasattr(yolo_model, 'predict'):\n",
        "                results = yolo_model.predict(img, conf=0.25, verbose=False)\n",
        "                for result in results:\n",
        "                    boxes = result.boxes\n",
        "                    if boxes is not None:\n",
        "                        for box in boxes:\n",
        "                            # Get box coordinates\n",
        "                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                            conf = box.conf[0].cpu().numpy()\n",
        "                            cls = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "                            # COCO class names\n",
        "                            class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "                                         'bus', 'train', 'truck', 'boat', 'traffic light']\n",
        "\n",
        "                            if cls < len(class_names):\n",
        "                                class_name = class_names[cls]\n",
        "                                # Only keep vehicle-related detections\n",
        "                                if class_name in ['car', 'truck', 'bus', 'motorcycle', 'bicycle']:\n",
        "                                    vehicles.append({\n",
        "                                        'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
        "                                        'confidence': float(conf),\n",
        "                                        'class': class_name\n",
        "                                    })\n",
        "                return vehicles\n",
        "        except Exception as e:\n",
        "            print(f\"Ultralytics approach failed: {e}\")\n",
        "\n",
        "        # Method 2: Try traditional torch hub approach\n",
        "        try:\n",
        "            # Convert BGR to RGB for YOLOv5\n",
        "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Run inference\n",
        "            results = yolo_model(rgb_img, size=640)\n",
        "\n",
        "            # Parse results - try pandas format first\n",
        "            try:\n",
        "                detections = results.pandas().xyxy[0]\n",
        "                for _, detection in detections.iterrows():\n",
        "                    class_name = detection['name']\n",
        "                    if class_name in ['car', 'truck', 'bus', 'motorcycle', 'bicycle', 'person']:\n",
        "                        vehicles.append({\n",
        "                            'bbox': [int(detection['xmin']), int(detection['ymin']),\n",
        "                                    int(detection['xmax']), int(detection['ymax'])],\n",
        "                            'confidence': float(detection['confidence']),\n",
        "                            'class': class_name\n",
        "                        })\n",
        "            except:\n",
        "                # Try tensor format\n",
        "                detections = results.xyxy[0].cpu().numpy()\n",
        "                class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "                             'bus', 'train', 'truck', 'boat']\n",
        "\n",
        "                for detection in detections:\n",
        "                    x1, y1, x2, y2, conf, cls = detection\n",
        "                    cls = int(cls)\n",
        "                    if cls < len(class_names):\n",
        "                        class_name = class_names[cls]\n",
        "                        if class_name in ['car', 'truck', 'bus', 'motorcycle', 'bicycle', 'person']:\n",
        "                            vehicles.append({\n",
        "                                'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
        "                                'confidence': float(conf),\n",
        "                                'class': class_name\n",
        "                            })\n",
        "\n",
        "            return vehicles\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Traditional approach failed: {e}\")\n",
        "            return vehicles\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Vehicle detection error: {e}\")\n",
        "        return vehicles\n",
        "\n",
        "def draw_vehicle_detections(img, vehicles):\n",
        "    \"\"\"Draw vehicle detection boxes with distance calculation and collision warnings\"\"\"\n",
        "    colors = {\n",
        "        'car': (0, 255, 255),      # Yellow\n",
        "        'truck': (255, 0, 255),    # Magenta\n",
        "        'bus': (255, 165, 0),      # Orange\n",
        "        'motorcycle': (0, 255, 0), # Green\n",
        "        'bicycle': (255, 0, 0),    # Blue\n",
        "        'person': (0, 0, 255)      # Red\n",
        "    }\n",
        "\n",
        "    img_height, img_width = img.shape[:2]\n",
        "    vehicles_in_front = []\n",
        "\n",
        "    for vehicle in vehicles:\n",
        "        bbox = vehicle['bbox']\n",
        "        confidence = vehicle['confidence']\n",
        "        class_name = vehicle['class']\n",
        "\n",
        "        # Calculate distance\n",
        "        distance = calculate_vehicle_distance(bbox, img_height)\n",
        "\n",
        "        # Check if vehicle is in front\n",
        "        in_front = is_vehicle_in_front(bbox, img_width)\n",
        "\n",
        "        if in_front and class_name in ['car', 'truck', 'bus']:\n",
        "            vehicles_in_front.append({'vehicle': vehicle, 'distance': distance})\n",
        "\n",
        "        # Get color for this class\n",
        "        color = colors.get(class_name, (0, 255, 255))\n",
        "\n",
        "        # Determine box thickness based on distance and position\n",
        "        thickness = 5 if (in_front and distance < 20) else 3\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness)\n",
        "\n",
        "        # Prepare label with distance\n",
        "        label = f\"{class_name}: {confidence:.2f}\"\n",
        "        distance_label = f\"Dist: {distance:.1f}m\"\n",
        "\n",
        "        # Draw labels\n",
        "        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
        "        dist_label_size = cv2.getTextSize(distance_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
        "\n",
        "        # Main label background\n",
        "        cv2.rectangle(img, (bbox[0], bbox[1] - label_size[1] - 25),\n",
        "                     (bbox[0] + max(label_size[0], dist_label_size[0]) + 10, bbox[1]), color, -1)\n",
        "\n",
        "        # Draw label text\n",
        "        cv2.putText(img, label, (bbox[0] + 5, bbox[1] - 15),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
        "        cv2.putText(img, distance_label, (bbox[0] + 5, bbox[1] - 5),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "\n",
        "        # Draw collision warning for vehicles too close\n",
        "        if in_front and distance < 15 and class_name in ['car', 'truck', 'bus']:\n",
        "            # Draw warning above the vehicle\n",
        "            warning_y = max(bbox[1] - 60, 30)\n",
        "\n",
        "            if distance < 8:  # Critical distance\n",
        "                warning_color = (0, 0, 255)  # Red\n",
        "                warning_text = \"TOO CLOSE!\"\n",
        "            elif distance < 12:  # Warning distance\n",
        "                warning_color = (0, 165, 255)  # Orange\n",
        "                warning_text = \"CLOSE!\"\n",
        "            else:  # Caution distance\n",
        "                warning_color = (0, 255, 255)  # Yellow\n",
        "                warning_text = \"CAUTION\"\n",
        "\n",
        "            # Warning box\n",
        "            warning_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
        "            cv2.rectangle(img, (bbox[0], warning_y - 25),\n",
        "                         (bbox[0] + warning_size[0] + 10, warning_y + 5), warning_color, -1)\n",
        "            cv2.rectangle(img, (bbox[0], warning_y - 25),\n",
        "                         (bbox[0] + warning_size[0] + 10, warning_y + 5), (255, 255, 255), 2)\n",
        "\n",
        "            # Warning text\n",
        "            cv2.putText(img, warning_text, (bbox[0] + 5, warning_y - 5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    # Draw overall collision warning if any vehicle is too close\n",
        "    if vehicles_in_front:\n",
        "        closest_distance = min([v['distance'] for v in vehicles_in_front])\n",
        "        if closest_distance < 10:\n",
        "            # Draw main collision warning\n",
        "            cv2.rectangle(img, (img_width - 300, 50), (img_width - 50, 120), (0, 0, 255), -1)\n",
        "            cv2.rectangle(img, (img_width - 300, 50), (img_width - 50, 120), (255, 255, 255), 3)\n",
        "\n",
        "            cv2.putText(img, \"COLLISION\", (img_width - 280, 80),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "            cv2.putText(img, \"WARNING!\", (img_width - 270, 105),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "# Step 5: Enhanced sliding window with better lane detection\n",
        "def get_hist(img):\n",
        "    return np.sum(img[img.shape[0]//2:, :], axis=0)\n",
        "\n",
        "def sliding_window(img, nwindows=9, margin=120, minpix=50, draw_windows=False):\n",
        "    global left_a, left_b, left_c, right_a, right_b, right_c\n",
        "\n",
        "    left_fit_ = np.empty(3)\n",
        "    right_fit_ = np.empty(3)\n",
        "    out_img = np.dstack((img, img, img)) * 255\n",
        "\n",
        "    histogram = get_hist(img)\n",
        "    midpoint = int(histogram.shape[0] / 2)\n",
        "    leftx_base = np.argmax(histogram[:midpoint])\n",
        "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "\n",
        "    window_height = int(img.shape[0] / nwindows)\n",
        "\n",
        "    nonzero = img.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "\n",
        "    leftx_current = leftx_base\n",
        "    rightx_current = rightx_base\n",
        "\n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "\n",
        "    for window in range(nwindows):\n",
        "        win_y_low = img.shape[0] - (window + 1) * window_height\n",
        "        win_y_high = img.shape[0] - window * window_height\n",
        "        win_xleft_low = leftx_current - margin\n",
        "        win_xleft_high = leftx_current + margin\n",
        "        win_xright_low = rightx_current - margin\n",
        "        win_xright_high = rightx_current + margin\n",
        "\n",
        "        if draw_windows:\n",
        "            cv2.rectangle(out_img, (win_xleft_low, win_y_low),\n",
        "                         (win_xleft_high, win_y_high), (100, 255, 255), 3)\n",
        "            cv2.rectangle(out_img, (win_xright_low, win_y_low),\n",
        "                         (win_xright_high, win_y_high), (100, 255, 255), 3)\n",
        "\n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
        "\n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "\n",
        "        if len(good_left_inds) > minpix:\n",
        "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:\n",
        "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "    left_lane_inds = np.concatenate(left_lane_inds)\n",
        "    right_lane_inds = np.concatenate(right_lane_inds)\n",
        "\n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds]\n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "    if len(leftx) > 0 and len(rightx) > 0:\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "        left_a.append(left_fit[0])\n",
        "        left_b.append(left_fit[1])\n",
        "        left_c.append(left_fit[2])\n",
        "\n",
        "        right_a.append(right_fit[0])\n",
        "        right_b.append(right_fit[1])\n",
        "        right_c.append(right_fit[2])\n",
        "\n",
        "        left_fit_[0] = np.mean(left_a[-10:])\n",
        "        left_fit_[1] = np.mean(left_b[-10:])\n",
        "        left_fit_[2] = np.mean(left_c[-10:])\n",
        "\n",
        "        right_fit_[0] = np.mean(right_a[-10:])\n",
        "        right_fit_[1] = np.mean(right_b[-10:])\n",
        "        right_fit_[2] = np.mean(right_c[-10:])\n",
        "    else:\n",
        "        left_fit_ = [0, 0, leftx_base] if len(left_a) == 0 else [np.mean(left_a[-5:]), np.mean(left_b[-5:]), np.mean(left_c[-5:])]\n",
        "        right_fit_ = [0, 0, rightx_base] if len(right_a) == 0 else [np.mean(right_a[-5:]), np.mean(right_b[-5:]), np.mean(right_c[-5:])]\n",
        "\n",
        "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
        "    left_fitx = left_fit_[0] * ploty ** 2 + left_fit_[1] * ploty + left_fit_[2]\n",
        "    right_fitx = right_fit_[0] * ploty ** 2 + right_fit_[1] * ploty + right_fit_[2]\n",
        "\n",
        "    if len(leftx) > 0:\n",
        "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 100]\n",
        "    if len(rightx) > 0:\n",
        "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 100, 255]\n",
        "\n",
        "    return out_img, (left_fitx, right_fitx), (left_fit_, right_fit_), ploty\n",
        "\n",
        "# Step 6: Enhanced curvature calculation with curve warning\n",
        "def get_curve(img, leftx, rightx):\n",
        "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
        "    y_eval = np.max(ploty)\n",
        "    ym_per_pix = 30.5 / 720\n",
        "    xm_per_pix = 3.7 / 720\n",
        "\n",
        "    left_fit_cr = np.polyfit(ploty * ym_per_pix, leftx * xm_per_pix, 2)\n",
        "    right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix, 2)\n",
        "\n",
        "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * left_fit_cr[0] + 1e-6)\n",
        "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * right_fit_cr[0] + 1e-6)\n",
        "\n",
        "    car_pos = img.shape[1] / 2\n",
        "    l_fit_x_int = left_fit_cr[0] * img.shape[0] ** 2 + left_fit_cr[1] * img.shape[0] + left_fit_cr[2]\n",
        "    r_fit_x_int = right_fit_cr[0] * img.shape[0] ** 2 + right_fit_cr[1] * img.shape[0] + right_fit_cr[2]\n",
        "    lane_center_position = (r_fit_x_int + l_fit_x_int) / 2\n",
        "    center = (car_pos - lane_center_position) * xm_per_pix / 10\n",
        "\n",
        "    return left_curverad, right_curverad, center\n",
        "\n",
        "# Global variables for curve detection\n",
        "curve_warning_counter = 0\n",
        "last_curvature_values = []\n",
        "\n",
        "def analyze_curve_severity(curvature):\n",
        "    \"\"\"Analyze curve severity and return warning level\"\"\"\n",
        "    global last_curvature_values\n",
        "\n",
        "    # Store last 10 curvature values for smoothing\n",
        "    last_curvature_values.append(curvature)\n",
        "    if len(last_curvature_values) > 10:\n",
        "        last_curvature_values.pop(0)\n",
        "\n",
        "    avg_curvature = np.mean(last_curvature_values)\n",
        "\n",
        "    if avg_curvature < 200:\n",
        "        return \"SHARP_CURVE\"\n",
        "    elif avg_curvature < 400:\n",
        "        return \"MODERATE_CURVE\"\n",
        "    elif avg_curvature < 800:\n",
        "        return \"GENTLE_CURVE\"\n",
        "    else:\n",
        "        return \"STRAIGHT\"\n",
        "\n",
        "def draw_lanes(img, left_fit, right_fit):\n",
        "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
        "    color_img = np.zeros_like(img)\n",
        "\n",
        "    left_points = np.array([np.transpose(np.vstack([left_fit, ploty]))])\n",
        "    right_points = np.array([np.flipud(np.transpose(np.vstack([right_fit, ploty])))])\n",
        "    points = np.hstack((left_points, right_points))\n",
        "\n",
        "    cv2.fillPoly(color_img, np.int_(points), (0, 255, 0))\n",
        "    inv_perspective = inv_perspective_warp(color_img)\n",
        "    img_out = cv2.addWeighted(img, 1, inv_perspective, 0.7, 0)\n",
        "    return img_out\n",
        "\n",
        "def calculate_vehicle_distance(bbox, img_height):\n",
        "    \"\"\"Calculate approximate distance to vehicle based on bounding box position and size\"\"\"\n",
        "    # Vehicle bottom y-coordinate\n",
        "    vehicle_bottom_y = bbox[3]\n",
        "\n",
        "    # Vehicle height in pixels\n",
        "    vehicle_height = bbox[3] - bbox[1]\n",
        "\n",
        "    # Approximate distance calculation (empirical formula)\n",
        "    # Assumes average car height of 1.5 meters\n",
        "    if vehicle_height > 0:\n",
        "        # Distance in meters (approximate)\n",
        "        distance = (1.5 * 720) / vehicle_height  # Normalized for 720p\n",
        "\n",
        "        # Adjust based on vertical position (perspective effect)\n",
        "        y_factor = (img_height - vehicle_bottom_y) / img_height\n",
        "        distance = distance * (0.5 + y_factor * 1.5)\n",
        "\n",
        "        return max(distance, 1.0)  # Minimum 1 meter\n",
        "\n",
        "    return 50.0  # Default distance if calculation fails\n",
        "\n",
        "def is_vehicle_in_front(bbox, img_width):\n",
        "    \"\"\"Check if vehicle is directly in front (in ego lane)\"\"\"\n",
        "    vehicle_center_x = (bbox[0] + bbox[2]) / 2\n",
        "    img_center_x = img_width / 2\n",
        "\n",
        "    # Check if vehicle is in the center lane area (Â±25% of image width)\n",
        "    lane_width_tolerance = img_width * 0.25\n",
        "\n",
        "    return abs(vehicle_center_x - img_center_x) < lane_width_tolerance\n",
        "\n",
        "def draw_enhanced_curve_warning(img, curvature):\n",
        "    \"\"\"Draw enhanced curve warning with different severity levels\"\"\"\n",
        "    global curve_warning_counter\n",
        "\n",
        "    curve_type = analyze_curve_severity(curvature)\n",
        "\n",
        "    if curve_type != \"STRAIGHT\":\n",
        "        curve_warning_counter = max(curve_warning_counter, 30)  # Show for at least 30 frames\n",
        "\n",
        "    if curve_warning_counter > 0:\n",
        "        curve_warning_counter -= 1\n",
        "\n",
        "        # Color and message based on severity\n",
        "        if curve_type == \"SHARP_CURVE\":\n",
        "            color = (0, 0, 255)  # Red\n",
        "            warning_msg = \"SHARP CURVE AHEAD!\"\n",
        "            sub_msg = \"REDUCE SPEED\"\n",
        "        elif curve_type == \"MODERATE_CURVE\":\n",
        "            color = (0, 165, 255)  # Orange\n",
        "            warning_msg = \"CURVE AHEAD!\"\n",
        "            sub_msg = \"SLOW DOWN\"\n",
        "        else:  # GENTLE_CURVE\n",
        "            color = (0, 255, 255)  # Yellow\n",
        "            warning_msg = \"GENTLE CURVE\"\n",
        "            sub_msg = \"CAUTION\"\n",
        "\n",
        "        # Draw warning box with pulsing effect\n",
        "        pulse = int(20 * (1 + 0.3 * np.sin(curve_warning_counter * 0.3)))\n",
        "\n",
        "        cv2.rectangle(img, (50, 50), (450, 130), color, -1)\n",
        "        cv2.rectangle(img, (50, 50), (450, 130), (255, 255, 255), 4)\n",
        "\n",
        "        # Warning text\n",
        "        cv2.putText(img, warning_msg, (70, 85),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)\n",
        "        cv2.putText(img, sub_msg, (150, 115),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        # Curvature value\n",
        "        cv2.putText(img, f\"R: {curvature:.0f}m\", (350, 115),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "# Step 7: Enhanced video processing pipeline\n",
        "def vid_pipeline(img):\n",
        "    \"\"\"Main video processing pipeline with enhanced curve detection and collision warnings\"\"\"\n",
        "    try:\n",
        "        # Lane detection\n",
        "        img_bin = pipeline(img)\n",
        "        img_warp = perspective_warp(img_bin)\n",
        "        out_img, curves, lanes, ploty = sliding_window(img_warp, draw_windows=False)\n",
        "\n",
        "        # Calculate curvature\n",
        "        curverad = get_curve(img, curves[0], curves[1])\n",
        "        lane_curve = np.mean([curverad[0], curverad[1]])\n",
        "\n",
        "        # Draw lanes\n",
        "        img_out = draw_lanes(img, curves[0], curves[1])\n",
        "\n",
        "        # Vehicle detection and distance calculation\n",
        "        vehicles = detect_vehicles(img_out)\n",
        "        img_out = draw_vehicle_detections(img_out, vehicles)\n",
        "\n",
        "        # Enhanced curve warning system\n",
        "        img_out = draw_enhanced_curve_warning(img_out, lane_curve)\n",
        "\n",
        "        # Enhanced information display with better background\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        fontColor = (255, 255, 255)\n",
        "        fontSize = 0.6\n",
        "        thickness = 2\n",
        "\n",
        "        # Larger background for text with transparency effect\n",
        "        overlay = img_out.copy()\n",
        "        cv2.rectangle(overlay, (10, img_out.shape[0] - 120), (500, img_out.shape[0] - 10), (0, 0, 0), -1)\n",
        "        img_out = cv2.addWeighted(img_out, 0.7, overlay, 0.3, 0)\n",
        "\n",
        "        # Display enhanced information\n",
        "        cv2.putText(img_out, f'Lane Curvature: {lane_curve:.0f} m',\n",
        "                   (20, img_out.shape[0] - 95), font, fontSize, fontColor, thickness)\n",
        "        cv2.putText(img_out, f'Vehicle Offset: {curverad[2]:.3f} m',\n",
        "                   (20, img_out.shape[0] - 70), font, fontSize, fontColor, thickness)\n",
        "        cv2.putText(img_out, f'Vehicles Detected: {len(vehicles)}',\n",
        "                   (20, img_out.shape[0] - 45), font, fontSize, fontColor, thickness)\n",
        "\n",
        "        # Add curve type information\n",
        "        curve_type = analyze_curve_severity(lane_curve)\n",
        "        curve_status = curve_type.replace('_', ' ').title()\n",
        "        cv2.putText(img_out, f'Road Status: {curve_status}',\n",
        "                   (20, img_out.shape[0] - 20), font, fontSize, fontColor, thickness)\n",
        "\n",
        "        return img_out\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Pipeline error: {e}\")\n",
        "        return img\n",
        "\n",
        "# Step 8: Main execution with better error handling\n",
        "def main():\n",
        "    \"\"\"Main function to run the enhanced lane detection\"\"\"\n",
        "    # Run calibration\n",
        "    print(\"Running camera calibration...\")\n",
        "    undistort_img()\n",
        "\n",
        "    # Test YOLO model with a sample\n",
        "    print(\"Testing YOLO model...\")\n",
        "    if yolo_model is not None:\n",
        "        try:\n",
        "            # Create a test image\n",
        "            test_img = np.ones((480, 640, 3), dtype=np.uint8) * 128\n",
        "            test_vehicles = detect_vehicles(test_img)\n",
        "            print(f\"YOLO model test: {len(test_vehicles)} vehicles detected in test image\")\n",
        "        except Exception as e:\n",
        "            print(f\"YOLO test failed: {e}\")\n",
        "    else:\n",
        "        print(\"Warning: YOLO model not loaded properly\")\n",
        "\n",
        "    # Check if video exists\n",
        "    video_path = 'project_video.mp4'\n",
        "    if not os.path.exists(video_path):\n",
        "        # Try alternative names\n",
        "        alternative_paths = ['project_video.mov', 'video.mp4', 'test_video.mp4', 'input.mp4']\n",
        "        found = False\n",
        "        for alt_path in alternative_paths:\n",
        "            if os.path.exists(alt_path):\n",
        "                video_path = alt_path\n",
        "                found = True\n",
        "                print(f\"Found video: {video_path}\")\n",
        "                break\n",
        "\n",
        "        if not found:\n",
        "            print(f\"Video file not found. Tried: {video_path}, {', '.join(alternative_paths)}\")\n",
        "            print(\"Please upload your video file and update the video_path variable.\")\n",
        "            return\n",
        "\n",
        "    # Process video\n",
        "    print(\"Processing video...\")\n",
        "    try:\n",
        "        myclip = VideoFileClip(video_path)\n",
        "        output_vid = 'enhanced_lane_detection_output.mp4'\n",
        "\n",
        "        print(f\"Video duration: {myclip.duration:.2f} seconds\")\n",
        "        print(f\"Video size: {myclip.size}\")\n",
        "        print(f\"Video FPS: {myclip.fps}\")\n",
        "\n",
        "        # Process with higher quality settings\n",
        "        clip = myclip.fl_image(vid_pipeline)\n",
        "        clip.write_videofile(output_vid,\n",
        "                           audio=False,\n",
        "                           codec='libx264',\n",
        "                           temp_audiofile='temp-audio.m4a',\n",
        "                           remove_temp=True,\n",
        "                           verbose=False,\n",
        "                           logger=None)\n",
        "\n",
        "        print(f\"Video processing complete! Output saved as: {output_vid}\")\n",
        "\n",
        "        # Display video\n",
        "        return HTML(f\"\"\"\n",
        "        <video width=\"1280\" height=\"720\" controls>\n",
        "          <source src=\"{output_vid}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "        \"\"\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Video processing error: {e}\")\n",
        "        print(\"Make sure your video file exists and is accessible.\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    result = main()\n",
        "    if result:\n",
        "        display(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StUwmgygTjHR",
        "outputId": "a1fc7983-6735-41f5-e904-e34428f18fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing YOLOv5...\n",
            "Ultralytics installed successfully\n",
            "Custom model not found, using YOLOv5s pretrained...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ 2025-7-26 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 216MB/s]\n",
            "\n",
            "Fusing layers... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/lane_detection\n",
        "%cd Curved-Lane-Lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-KRBN3oYIRy",
        "outputId": "7797df85-ed5f-4c99-fbaa-198088f0fcae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lane_detection\n",
            "/content/lane_detection/Curved-Lane-Lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from moviepy.editor import VideoFileClip\n",
        "from IPython.display import HTML\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install YOLOv5 if not already installed\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install_yolov5():\n",
        "    \"\"\"Install YOLOv5 dependencies\"\"\"\n",
        "    try:\n",
        "        # Try to install ultralytics first (more reliable)\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ultralytics\", \"-q\"])\n",
        "        print(\"Ultralytics installed successfully\")\n",
        "    except:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"yolov5\", \"-q\"])\n",
        "            print(\"YOLOv5 installed successfully\")\n",
        "        except:\n",
        "            print(\"Failed to install YOLOv5 packages\")\n",
        "\n",
        "    try:\n",
        "        # Try custom model first\n",
        "        if os.path.exists('best.pt'):\n",
        "            print(\"Loading custom YOLOv5 model...\")\n",
        "            model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True, trust_repo=True)\n",
        "        else:\n",
        "            print(\"Custom model not found, using YOLOv5s pretrained...\")\n",
        "            model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, trust_repo=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from hub: {e}\")\n",
        "        print(\"Trying alternative approach...\")\n",
        "        try:\n",
        "            # Alternative: use ultralytics YOLO\n",
        "            from ultralytics import YOLO\n",
        "            model = YOLO('yolov5s.pt')\n",
        "            print(\"Loaded YOLOv5s using ultralytics\")\n",
        "        except:\n",
        "            print(\"Failed to load any YOLO model, using dummy detector\")\n",
        "            return None\n",
        "\n",
        "    # Set device\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    if model is not None:\n",
        "        try:\n",
        "            model.to(device)\n",
        "        except:\n",
        "            pass\n",
        "        print(f\"YOLOv5 loaded on {device}\")\n",
        "    return model\n",
        "\n",
        "# Initialize YOLOv5\n",
        "print(\"Initializing YOLOv5...\")\n",
        "yolo_model = install_yolov5()\n",
        "\n",
        "# Configure YOLOv5 for better performance\n",
        "if yolo_model is not None:\n",
        "    try:\n",
        "        yolo_model.conf = 0.25  # Lower confidence threshold for better detection\n",
        "        yolo_model.iou = 0.45   # IoU threshold for NMS\n",
        "        # Include more vehicle classes\n",
        "        yolo_model.classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]  # person, bicycle, car, motorcycle, airplane, bus, train, truck, boat\n",
        "    except:\n",
        "        print(\"Using default YOLO settings\")\n",
        "\n",
        "# Step 1: Camera calibration and undistortion\n",
        "def undistort_img():\n",
        "    \"\"\"Camera calibration function\"\"\"\n",
        "    objp = np.zeros((6*9, 3), dtype=np.float32)\n",
        "    objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
        "\n",
        "    objpoints = []\n",
        "    imgpoints = []\n",
        "\n",
        "    # Create camera_cal directory if it doesn't exist\n",
        "    os.makedirs('camera_cal', exist_ok=True)\n",
        "\n",
        "    images = glob.glob('camera_cal/*.jpg')\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(\"No calibration images found. Creating dummy calibration...\")\n",
        "        # Create dummy calibration parameters for demo\n",
        "        img_size = (1280, 720)\n",
        "        mtx = np.array([[1.15777930e+03, 0.00000000e+00, 6.67111054e+02],\n",
        "                       [0.00000000e+00, 1.15282291e+03, 3.86128938e+02],\n",
        "                       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
        "        dist = np.array([[-2.42565104e-01, -4.77893070e-02, -1.31388084e-03, -8.79107779e-05, 2.20573263e-02]])\n",
        "\n",
        "        dist_pickle = {'mtx': mtx, 'dist': dist}\n",
        "        pickle.dump(dist_pickle, open('camera_cal/cal_pickle.p', 'wb'))\n",
        "        print(\"Dummy calibration created successfully\")\n",
        "        return\n",
        "\n",
        "    for fname in images:\n",
        "        img = cv2.imread(fname)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
        "\n",
        "        if ret:\n",
        "            objpoints.append(objp.copy())\n",
        "            imgpoints.append(corners)\n",
        "\n",
        "    if len(objpoints) > 0:\n",
        "        img_size = (img.shape[1], img.shape[0])\n",
        "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
        "\n",
        "        dist_pickle = {'mtx': mtx, 'dist': dist}\n",
        "        pickle.dump(dist_pickle, open('camera_cal/cal_pickle.p', 'wb'))\n",
        "        print(\"Camera calibration successful:\", ret)\n",
        "    else:\n",
        "        print(\"No valid calibration images found\")\n",
        "\n",
        "def undistort(img, cal_dir='camera_cal/cal_pickle.p'):\n",
        "    \"\"\"Undistort image using calibration parameters\"\"\"\n",
        "    try:\n",
        "        with open(cal_dir, 'rb') as f:\n",
        "            calib = pickle.load(f)\n",
        "        mtx = calib['mtx']\n",
        "        dist = calib['dist']\n",
        "        return cv2.undistort(img, mtx, dist, None, mtx)\n",
        "    except:\n",
        "        return img  # Return original if calibration fails\n",
        "\n",
        "# Step 2: Enhanced image processing pipeline\n",
        "def pipeline(img, s_thresh=(100, 255), sx_thresh=(15, 255)):\n",
        "    \"\"\"Enhanced image processing pipeline with better filtering\"\"\"\n",
        "    img = undistort(img)\n",
        "    img = np.copy(img)\n",
        "\n",
        "    # Convert to HLS color space\n",
        "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(float)\n",
        "    h_channel = hls[:, :, 0]\n",
        "    l_channel = hls[:, :, 1]\n",
        "    s_channel = hls[:, :, 2]\n",
        "\n",
        "    # Enhanced yellow line detection\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Yellow mask\n",
        "    yellow_lower = np.array([15, 100, 120])\n",
        "    yellow_upper = np.array([35, 255, 255])\n",
        "    yellow_mask = cv2.inRange(hsv, yellow_lower, yellow_upper)\n",
        "\n",
        "    # White mask\n",
        "    white_lower = np.array([0, 0, 200])\n",
        "    white_upper = np.array([255, 30, 255])\n",
        "    white_mask = cv2.inRange(hsv, white_lower, white_upper)\n",
        "\n",
        "    # Sobel x gradient\n",
        "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0, ksize=7)\n",
        "    abs_sobelx = np.absolute(sobelx)\n",
        "    scaled_sobel = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))\n",
        "\n",
        "    sxbinary = np.zeros_like(scaled_sobel)\n",
        "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
        "\n",
        "    # S channel threshold\n",
        "    s_binary = np.zeros_like(s_channel)\n",
        "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
        "\n",
        "    # Combine all thresholds\n",
        "    combined_binary = np.zeros_like(sxbinary)\n",
        "    combined_binary[(s_binary == 1) | (sxbinary == 1) | (yellow_mask == 255) | (white_mask == 255)] = 1\n",
        "\n",
        "    return combined_binary\n",
        "\n",
        "# Step 3: Perspective transformation\n",
        "def perspective_warp(img,\n",
        "                    dst_size=(1280, 720),\n",
        "                    src=np.float32([(0.43, 0.65), (0.58, 0.65), (0.1, 1), (1, 1)]),\n",
        "                    dst=np.float32([(0, 0), (1, 0), (0, 1), (1, 1)])):\n",
        "    img_size = np.float32([(img.shape[1], img.shape[0])])\n",
        "    src = src * img_size\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    warped = cv2.warpPerspective(img, M, dst_size)\n",
        "    return warped\n",
        "\n",
        "def inv_perspective_warp(img,\n",
        "                         dst_size=(1280, 720),\n",
        "                         src=np.float32([(0, 0), (1, 0), (0, 1), (1, 1)]),\n",
        "                         dst=np.float32([(0.43, 0.65), (0.58, 0.65), (0.1, 1), (1, 1)])):\n",
        "    img_size = np.float32([(img.shape[1], img.shape[0])])\n",
        "    src = src * img_size\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    warped = cv2.warpPerspective(img, M, dst_size)\n",
        "    return warped\n",
        "\n",
        "# Global variables for lane tracking\n",
        "left_a, left_b, left_c = [], [], []\n",
        "right_a, right_b, right_c = [], [], []\n",
        "\n",
        "# Step 4: Enhanced Vehicle detection with multiple approaches\n",
        "def detect_vehicles(img):\n",
        "    \"\"\"Detect vehicles using YOLOv5 with multiple fallback approaches\"\"\"\n",
        "    vehicles = []\n",
        "\n",
        "    if yolo_model is None:\n",
        "        return vehicles\n",
        "\n",
        "    try:\n",
        "        # Method 1: Try ultralytics YOLO approach\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "            if hasattr(yolo_model, 'predict'):\n",
        "                results = yolo_model.predict(img, conf=0.25, verbose=False)\n",
        "                for result in results:\n",
        "                    boxes = result.boxes\n",
        "                    if boxes is not None:\n",
        "                        for box in boxes:\n",
        "                            # Get box coordinates\n",
        "                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                            conf = box.conf[0].cpu().numpy()\n",
        "                            cls = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "                            # COCO class names\n",
        "                            class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "                                         'bus', 'train', 'truck', 'boat', 'traffic light']\n",
        "\n",
        "                            if cls < len(class_names):\n",
        "                                class_name = class_names[cls]\n",
        "                                # Only keep vehicle-related detections\n",
        "                                if class_name in ['car', 'truck', 'bus', 'motorcycle', 'bicycle']:\n",
        "                                    vehicles.append({\n",
        "                                        'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
        "                                        'confidence': float(conf),\n",
        "                                        'class': class_name\n",
        "                                    })\n",
        "                return vehicles\n",
        "        except Exception as e:\n",
        "            print(f\"Ultralytics approach failed: {e}\")\n",
        "\n",
        "        # Method 2: Try traditional torch hub approach\n",
        "        try:\n",
        "            # Convert BGR to RGB for YOLOv5\n",
        "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Run inference\n",
        "            results = yolo_model(rgb_img, size=640)\n",
        "\n",
        "            # Parse results - try pandas format first\n",
        "            try:\n",
        "                detections = results.pandas().xyxy[0]\n",
        "                for _, detection in detections.iterrows():\n",
        "                    class_name = detection['name']\n",
        "                    if class_name in ['car', 'truck', 'bus', 'motorcycle', 'bicycle', 'person']:\n",
        "                        vehicles.append({\n",
        "                            'bbox': [int(detection['xmin']), int(detection['ymin']),\n",
        "                                    int(detection['xmax']), int(detection['ymax'])],\n",
        "                            'confidence': float(detection['confidence']),\n",
        "                            'class': class_name\n",
        "                        })\n",
        "            except:\n",
        "                # Try tensor format\n",
        "                detections = results.xyxy[0].cpu().numpy()\n",
        "                class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "                             'bus', 'train', 'truck', 'boat']\n",
        "\n",
        "                for detection in detections:\n",
        "                    x1, y1, x2, y2, conf, cls = detection\n",
        "                    cls = int(cls)\n",
        "                    if cls < len(class_names):\n",
        "                        class_name = class_names[cls]\n",
        "                        if class_name in ['car', 'truck', 'bus', 'motorcycle', 'bicycle', 'person']:\n",
        "                            vehicles.append({\n",
        "                                'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
        "                                'confidence': float(conf),\n",
        "                                'class': class_name\n",
        "                            })\n",
        "\n",
        "            return vehicles\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Traditional approach failed: {e}\")\n",
        "            return vehicles\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Vehicle detection error: {e}\")\n",
        "        return vehicles\n",
        "\n",
        "def draw_vehicle_detections(img, vehicles):\n",
        "    \"\"\"Draw vehicle detection boxes with distance calculation and collision warnings\"\"\"\n",
        "    colors = {\n",
        "        'car': (0, 255, 255),      # Yellow\n",
        "        'truck': (255, 0, 255),    # Magenta\n",
        "        'bus': (255, 165, 0),      # Orange\n",
        "        'motorcycle': (0, 255, 0), # Green\n",
        "        'bicycle': (255, 0, 0),    # Blue\n",
        "        'person': (0, 0, 255)      # Red\n",
        "    }\n",
        "\n",
        "    img_height, img_width = img.shape[:2]\n",
        "    vehicles_in_front = []\n",
        "\n",
        "    for vehicle in vehicles:\n",
        "        bbox = vehicle['bbox']\n",
        "        confidence = vehicle['confidence']\n",
        "        class_name = vehicle['class']\n",
        "\n",
        "        # Calculate distance\n",
        "        distance = calculate_vehicle_distance(bbox, img_height)\n",
        "\n",
        "        # Check if vehicle is in front\n",
        "        in_front = is_vehicle_in_front(bbox, img_width)\n",
        "\n",
        "        if in_front and class_name in ['car', 'truck', 'bus']:\n",
        "            vehicles_in_front.append({'vehicle': vehicle, 'distance': distance})\n",
        "\n",
        "        # Get color for this class\n",
        "        color = colors.get(class_name, (0, 255, 255))\n",
        "\n",
        "        # Determine box thickness based on distance and position\n",
        "        thickness = 5 if (in_front and distance < 20) else 3\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness)\n",
        "\n",
        "        # Prepare label with distance\n",
        "        label = f\"{class_name}: {confidence:.2f}\"\n",
        "        distance_label = f\"Dist: {distance:.1f}m\"\n",
        "\n",
        "        # Draw labels\n",
        "        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
        "        dist_label_size = cv2.getTextSize(distance_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
        "\n",
        "        # Main label background\n",
        "        cv2.rectangle(img, (bbox[0], bbox[1] - label_size[1] - 25),\n",
        "                     (bbox[0] + max(label_size[0], dist_label_size[0]) + 10, bbox[1]), color, -1)\n",
        "\n",
        "        # Draw label text\n",
        "        cv2.putText(img, label, (bbox[0] + 5, bbox[1] - 15),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
        "        cv2.putText(img, distance_label, (bbox[0] + 5, bbox[1] - 5),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "\n",
        "        # Draw collision warning for vehicles too close\n",
        "        if in_front and distance < 15 and class_name in ['car', 'truck', 'bus']:\n",
        "            # Draw warning above the vehicle\n",
        "            warning_y = max(bbox[1] - 60, 30)\n",
        "\n",
        "            if distance < 8:  # Critical distance\n",
        "                warning_color = (0, 0, 255)  # Red\n",
        "                warning_text = \"TOO CLOSE!\"\n",
        "            elif distance < 12:  # Warning distance\n",
        "                warning_color = (0, 165, 255)  # Orange\n",
        "                warning_text = \"CLOSE!\"\n",
        "            else:  # Caution distance\n",
        "                warning_color = (0, 255, 255)  # Yellow\n",
        "                warning_text = \"CAUTION\"\n",
        "\n",
        "            # Warning box\n",
        "            warning_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
        "            cv2.rectangle(img, (bbox[0], warning_y - 25),\n",
        "                         (bbox[0] + warning_size[0] + 10, warning_y + 5), warning_color, -1)\n",
        "            cv2.rectangle(img, (bbox[0], warning_y - 25),\n",
        "                         (bbox[0] + warning_size[0] + 10, warning_y + 5), (255, 255, 255), 2)\n",
        "\n",
        "            # Warning text\n",
        "            cv2.putText(img, warning_text, (bbox[0] + 5, warning_y - 5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    # Draw overall collision warning if any vehicle is too close\n",
        "    if vehicles_in_front:\n",
        "        closest_distance = min([v['distance'] for v in vehicles_in_front])\n",
        "        if closest_distance < 10:\n",
        "            # Draw main collision warning\n",
        "            cv2.rectangle(img, (img_width - 300, 50), (img_width - 50, 120), (0, 0, 255), -1)\n",
        "            cv2.rectangle(img, (img_width - 300, 50), (img_width - 50, 120), (255, 255, 255), 3)\n",
        "\n",
        "            cv2.putText(img, \"COLLISION\", (img_width - 280, 80),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "            cv2.putText(img, \"WARNING!\", (img_width - 270, 105),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "# Step 5: Enhanced sliding window with better lane detection\n",
        "def get_hist(img):\n",
        "    return np.sum(img[img.shape[0]//2:, :], axis=0)\n",
        "\n",
        "def sliding_window(img, nwindows=9, margin=120, minpix=50, draw_windows=False):\n",
        "    global left_a, left_b, left_c, right_a, right_b, right_c\n",
        "\n",
        "    left_fit_ = np.empty(3)\n",
        "    right_fit_ = np.empty(3)\n",
        "    out_img = np.dstack((img, img, img)) * 255\n",
        "\n",
        "    histogram = get_hist(img)\n",
        "    midpoint = int(histogram.shape[0] / 2)\n",
        "    leftx_base = np.argmax(histogram[:midpoint])\n",
        "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "\n",
        "    window_height = int(img.shape[0] / nwindows)\n",
        "\n",
        "    nonzero = img.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "\n",
        "    leftx_current = leftx_base\n",
        "    rightx_current = rightx_base\n",
        "\n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "\n",
        "    for window in range(nwindows):\n",
        "        win_y_low = img.shape[0] - (window + 1) * window_height\n",
        "        win_y_high = img.shape[0] - window * window_height\n",
        "        win_xleft_low = leftx_current - margin\n",
        "        win_xleft_high = leftx_current + margin\n",
        "        win_xright_low = rightx_current - margin\n",
        "        win_xright_high = rightx_current + margin\n",
        "\n",
        "        if draw_windows:\n",
        "            cv2.rectangle(out_img, (win_xleft_low, win_y_low),\n",
        "                         (win_xleft_high, win_y_high), (100, 255, 255), 3)\n",
        "            cv2.rectangle(out_img, (win_xright_low, win_y_low),\n",
        "                         (win_xright_high, win_y_high), (100, 255, 255), 3)\n",
        "\n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
        "\n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "\n",
        "        if len(good_left_inds) > minpix:\n",
        "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:\n",
        "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "    left_lane_inds = np.concatenate(left_lane_inds)\n",
        "    right_lane_inds = np.concatenate(right_lane_inds)\n",
        "\n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds]\n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "    if len(leftx) > 0 and len(rightx) > 0:\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "        left_a.append(left_fit[0])\n",
        "        left_b.append(left_fit[1])\n",
        "        left_c.append(left_fit[2])\n",
        "\n",
        "        right_a.append(right_fit[0])\n",
        "        right_b.append(right_fit[1])\n",
        "        right_c.append(right_fit[2])\n",
        "\n",
        "        left_fit_[0] = np.mean(left_a[-10:])\n",
        "        left_fit_[1] = np.mean(left_b[-10:])\n",
        "        left_fit_[2] = np.mean(left_c[-10:])\n",
        "\n",
        "        right_fit_[0] = np.mean(right_a[-10:])\n",
        "        right_fit_[1] = np.mean(right_b[-10:])\n",
        "        right_fit_[2] = np.mean(right_c[-10:])\n",
        "    else:\n",
        "        left_fit_ = [0, 0, leftx_base] if len(left_a) == 0 else [np.mean(left_a[-5:]), np.mean(left_b[-5:]), np.mean(left_c[-5:])]\n",
        "        right_fit_ = [0, 0, rightx_base] if len(right_a) == 0 else [np.mean(right_a[-5:]), np.mean(right_b[-5:]), np.mean(right_c[-5:])]\n",
        "\n",
        "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
        "    left_fitx = left_fit_[0] * ploty ** 2 + left_fit_[1] * ploty + left_fit_[2]\n",
        "    right_fitx = right_fit_[0] * ploty ** 2 + right_fit_[1] * ploty + right_fit_[2]\n",
        "\n",
        "    if len(leftx) > 0:\n",
        "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 100]\n",
        "    if len(rightx) > 0:\n",
        "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 100, 255]\n",
        "\n",
        "    return out_img, (left_fitx, right_fitx), (left_fit_, right_fit_), ploty\n",
        "\n",
        "# Step 6: Enhanced curvature calculation with curve warning\n",
        "def get_curve(img, leftx, rightx):\n",
        "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
        "    y_eval = np.max(ploty)\n",
        "    ym_per_pix = 30.5 / 720\n",
        "    xm_per_pix = 3.7 / 720\n",
        "\n",
        "    left_fit_cr = np.polyfit(ploty * ym_per_pix, leftx * xm_per_pix, 2)\n",
        "    right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix, 2)\n",
        "\n",
        "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * left_fit_cr[0] + 1e-6)\n",
        "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * right_fit_cr[0] + 1e-6)\n",
        "\n",
        "    car_pos = img.shape[1] / 2\n",
        "    l_fit_x_int = left_fit_cr[0] * img.shape[0] ** 2 + left_fit_cr[1] * img.shape[0] + left_fit_cr[2]\n",
        "    r_fit_x_int = right_fit_cr[0] * img.shape[0] ** 2 + right_fit_cr[1] * img.shape[0] + right_fit_cr[2]\n",
        "    lane_center_position = (r_fit_x_int + l_fit_x_int) / 2\n",
        "    center = (car_pos - lane_center_position) * xm_per_pix / 10\n",
        "\n",
        "    return left_curverad, right_curverad, center\n",
        "\n",
        "# Global variables for curve detection\n",
        "curve_warning_counter = 0\n",
        "last_curvature_values = []\n",
        "\n",
        "def analyze_curve_severity(curvature):\n",
        "    \"\"\"Analyze curve severity and return warning level\"\"\"\n",
        "    global last_curvature_values\n",
        "\n",
        "    # Store last 10 curvature values for smoothing\n",
        "    last_curvature_values.append(curvature)\n",
        "    if len(last_curvature_values) > 10:\n",
        "        last_curvature_values.pop(0)\n",
        "\n",
        "    avg_curvature = np.mean(last_curvature_values)\n",
        "\n",
        "    if avg_curvature < 200:\n",
        "        return \"SHARP_CURVE\"\n",
        "    elif avg_curvature < 400:\n",
        "        return \"MODERATE_CURVE\"\n",
        "    elif avg_curvature < 800:\n",
        "        return \"GENTLE_CURVE\"\n",
        "    else:\n",
        "        return \"STRAIGHT\"\n",
        "\n",
        "def draw_lanes(img, left_fit, right_fit):\n",
        "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
        "    color_img = np.zeros_like(img)\n",
        "\n",
        "    left_points = np.array([np.transpose(np.vstack([left_fit, ploty]))])\n",
        "    right_points = np.array([np.flipud(np.transpose(np.vstack([right_fit, ploty])))])\n",
        "    points = np.hstack((left_points, right_points))\n",
        "\n",
        "    cv2.fillPoly(color_img, np.int_(points), (0, 255, 0))\n",
        "    inv_perspective = inv_perspective_warp(color_img)\n",
        "    img_out = cv2.addWeighted(img, 1, inv_perspective, 0.7, 0)\n",
        "    return img_out\n",
        "\n",
        "def calculate_vehicle_distance(bbox, img_height):\n",
        "    \"\"\"Calculate approximate distance to vehicle based on bounding box position and size\"\"\"\n",
        "    # Vehicle bottom y-coordinate\n",
        "    vehicle_bottom_y = bbox[3]\n",
        "\n",
        "    # Vehicle height in pixels\n",
        "    vehicle_height = bbox[3] - bbox[1]\n",
        "\n",
        "    # Approximate distance calculation (empirical formula)\n",
        "    # Assumes average car height of 1.5 meters\n",
        "    if vehicle_height > 0:\n",
        "        # Distance in meters (approximate)\n",
        "        distance = (1.5 * 720) / vehicle_height  # Normalized for 720p\n",
        "\n",
        "        # Adjust based on vertical position (perspective effect)\n",
        "        y_factor = (img_height - vehicle_bottom_y) / img_height\n",
        "        distance = distance * (0.5 + y_factor * 1.5)\n",
        "\n",
        "        return max(distance, 1.0)  # Minimum 1 meter\n",
        "\n",
        "    return 50.0  # Default distance if calculation fails\n",
        "\n",
        "def is_vehicle_in_front(bbox, img_width):\n",
        "    \"\"\"Check if vehicle is directly in front (in ego lane)\"\"\"\n",
        "    vehicle_center_x = (bbox[0] + bbox[2]) / 2\n",
        "    img_center_x = img_width / 2\n",
        "\n",
        "    # Check if vehicle is in the center lane area (Â±25% of image width)\n",
        "    lane_width_tolerance = img_width * 0.25\n",
        "\n",
        "    return abs(vehicle_center_x - img_center_x) < lane_width_tolerance\n",
        "\n",
        "def draw_enhanced_curve_warning(img, curvature):\n",
        "    \"\"\"Draw enhanced curve warning with improved styling\"\"\"\n",
        "    global curve_warning_counter\n",
        "\n",
        "    curve_type = analyze_curve_severity(curvature)\n",
        "\n",
        "    if curve_type != \"STRAIGHT\":\n",
        "        curve_warning_counter = max(curve_warning_counter, 30)  # Show for at least 30 frames\n",
        "\n",
        "    if curve_warning_counter > 0:\n",
        "        curve_warning_counter -= 1\n",
        "\n",
        "        # Get image dimensions for centering\n",
        "        img_height, img_width = img.shape[:2]\n",
        "\n",
        "        # Warning box dimensions\n",
        "        box_width = 380\n",
        "        box_height = 80\n",
        "        box_x = (img_width - box_width) // 2\n",
        "        box_y = 40\n",
        "\n",
        "        # Color and message based on severity\n",
        "        if curve_type == \"SHARP_CURVE\":\n",
        "            color = (0, 0, 255)  # Red\n",
        "            warning_msg = \"SHARP CURVE AHEAD!\"\n",
        "            sub_msg = \"REDUCE SPEED NOW\"\n",
        "        elif curve_type == \"MODERATE_CURVE\":\n",
        "            color = (0, 100, 255)  # Orange-Red\n",
        "            warning_msg = \"CURVE AHEAD!\"\n",
        "            sub_msg = \"SLOW DOWN\"\n",
        "        else:  # GENTLE_CURVE\n",
        "            color = (0, 200, 255)  # Yellow-Orange\n",
        "            warning_msg = \"GENTLE CURVE\"\n",
        "            sub_msg = \"CAUTION\"\n",
        "\n",
        "        # Draw main warning box with gradient effect\n",
        "        cv2.rectangle(img, (box_x, box_y), (box_x + box_width, box_y + box_height), color, -1)\n",
        "        cv2.rectangle(img, (box_x, box_y), (box_x + box_width, box_y + box_height), (255, 255, 255), 4)\n",
        "\n",
        "        # Inner shadow effect\n",
        "        cv2.rectangle(img, (box_x + 5, box_y + 5), (box_x + box_width - 5, box_y + box_height - 5),\n",
        "                     (255, 255, 255, 50), 2)\n",
        "\n",
        "        # Warning text with better positioning\n",
        "        # Main warning text\n",
        "        text_size = cv2.getTextSize(warning_msg, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 3)[0]\n",
        "        text_x = box_x + (box_width - text_size[0]) // 2\n",
        "        cv2.putText(img, warning_msg, (text_x, box_y + 35),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)\n",
        "\n",
        "        # Sub message\n",
        "        sub_size = cv2.getTextSize(sub_msg, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
        "        sub_x = box_x + (box_width - sub_size[0]) // 2\n",
        "        cv2.putText(img, sub_msg, (sub_x, box_y + 60),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        # Curvature value in top right corner of warning\n",
        "        cv2.putText(img, f\"R: {curvature:.0f}m\", (box_x + box_width - 90, box_y + 20),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "def draw_vehicle_detections(img, vehicles):\n",
        "    \"\"\"Draw vehicle detection boxes with improved styling and distance calculation\"\"\"\n",
        "    colors = {\n",
        "        'car': (0, 255, 255),      # Cyan\n",
        "        'truck': (128, 0, 255),    # Purple\n",
        "        'bus': (0, 165, 255),      # Orange\n",
        "        'motorcycle': (0, 255, 0), # Green\n",
        "        'bicycle': (255, 0, 0),    # Blue\n",
        "        'person': (0, 0, 255)      # Red\n",
        "    }\n",
        "\n",
        "    img_height, img_width = img.shape[:2]\n",
        "    vehicles_in_front = []\n",
        "\n",
        "    for vehicle in vehicles:\n",
        "        bbox = vehicle['bbox']\n",
        "        confidence = vehicle['confidence']\n",
        "        class_name = vehicle['class']\n",
        "\n",
        "        # Calculate distance\n",
        "        distance = calculate_vehicle_distance(bbox, img_height)\n",
        "\n",
        "        # Check if vehicle is in front\n",
        "        in_front = is_vehicle_in_front(bbox, img_width)\n",
        "\n",
        "        if in_front and class_name in ['car', 'truck', 'bus']:\n",
        "            vehicles_in_front.append({'vehicle': vehicle, 'distance': distance})\n",
        "\n",
        "        # Get color for this class\n",
        "        color = colors.get(class_name, (0, 255, 255))\n",
        "\n",
        "        # Determine box thickness based on distance and position\n",
        "        thickness = 4 if (in_front and distance < 20) else 2\n",
        "\n",
        "        # Draw bounding box with rounded corners effect\n",
        "        cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness)\n",
        "        cv2.rectangle(img, (bbox[0] - 2, bbox[1] - 2), (bbox[2] + 2, bbox[3] + 2), (255, 255, 255), 1)\n",
        "\n",
        "        # Create styled label background\n",
        "        label = f\"{class_name.upper()}: {confidence:.2f}\"\n",
        "        distance_label = f\"DIST: {distance:.1f}m\"\n",
        "\n",
        "        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
        "        dist_label_size = cv2.getTextSize(distance_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
        "\n",
        "        # Label background with proper spacing\n",
        "        max_width = max(label_size[0], dist_label_size[0]) + 20\n",
        "        label_height = 50\n",
        "\n",
        "        # Main label background with gradient effect\n",
        "        cv2.rectangle(img, (bbox[0], bbox[1] - label_height),\n",
        "                     (bbox[0] + max_width, bbox[1]), color, -1)\n",
        "        cv2.rectangle(img, (bbox[0], bbox[1] - label_height),\n",
        "                     (bbox[0] + max_width, bbox[1]), (255, 255, 255), 2)\n",
        "\n",
        "        # Draw label text with better positioning\n",
        "        cv2.putText(img, label, (bbox[0] + 10, bbox[1] - 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
        "        cv2.putText(img, distance_label, (bbox[0] + 10, bbox[1] - 10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "\n",
        "        # Draw enhanced collision warning for vehicles too close\n",
        "        if in_front and distance < 15 and class_name in ['car', 'truck', 'bus']:\n",
        "            draw_collision_warning(img, bbox, distance)\n",
        "\n",
        "    # Draw overall collision warning if any vehicle is too close\n",
        "    if vehicles_in_front:\n",
        "        closest_distance = min([v['distance'] for v in vehicles_in_front])\n",
        "        if closest_distance < 10:\n",
        "            draw_main_collision_warning(img, closest_distance)\n",
        "\n",
        "    return img\n",
        "\n",
        "def draw_collision_warning(img, bbox, distance):\n",
        "    \"\"\"Draw individual collision warning above vehicle\"\"\"\n",
        "    warning_y = max(bbox[1] - 80, 30)\n",
        "\n",
        "    if distance < 8:  # Critical distance\n",
        "        warning_color = (0, 0, 255)  # Red\n",
        "        warning_text = \"TOO CLOSE!\"\n",
        "    elif distance < 12:  # Warning distance\n",
        "        warning_color = (0, 100, 255)  # Orange\n",
        "        warning_text = \"CLOSE!\"\n",
        "    else:  # Caution distance\n",
        "        warning_color = (0, 200, 255)  # Yellow\n",
        "        warning_text = \"CAUTION\"\n",
        "\n",
        "    # Warning box with improved styling\n",
        "    warning_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
        "    box_width = warning_size[0] + 20\n",
        "    box_height = 35\n",
        "\n",
        "    cv2.rectangle(img, (bbox[0], warning_y - box_height),\n",
        "                 (bbox[0] + box_width, warning_y), warning_color, -1)\n",
        "    cv2.rectangle(img, (bbox[0], warning_y - box_height),\n",
        "                 (bbox[0] + box_width, warning_y), (255, 255, 255), 3)\n",
        "\n",
        "    # Warning text\n",
        "    text_x = bbox[0] + 10\n",
        "    cv2.putText(img, warning_text, (text_x, warning_y - 10),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "def draw_main_collision_warning(img, distance):\n",
        "    \"\"\"Draw main collision warning panel\"\"\"\n",
        "    img_height, img_width = img.shape[:2]\n",
        "\n",
        "    # Warning panel dimensions\n",
        "    panel_width = 280\n",
        "    panel_height = 80\n",
        "    panel_x = img_width - panel_width - 20\n",
        "    panel_y = 120\n",
        "\n",
        "    # Draw warning panel\n",
        "    cv2.rectangle(img, (panel_x, panel_y), (panel_x + panel_width, panel_y + panel_height),\n",
        "                 (0, 0, 255), -1)\n",
        "    cv2.rectangle(img, (panel_x, panel_y), (panel_x + panel_width, panel_y + panel_height),\n",
        "                 (255, 255, 255), 4)\n",
        "\n",
        "    # Warning text\n",
        "    cv2.putText(img, \"COLLISION WARNING!\", (panel_x + 20, panel_y + 30),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "    cv2.putText(img, f\"Distance: {distance:.1f}m\", (panel_x + 50, panel_y + 60),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "# Step 7: Enhanced video processing pipeline with improved visualization\n",
        "def vid_pipeline(img):\n",
        "    \"\"\"Main video processing pipeline with enhanced visualization and text layout\"\"\"\n",
        "    try:\n",
        "        # Lane detection\n",
        "        img_bin = pipeline(img)\n",
        "        img_warp = perspective_warp(img_bin)\n",
        "        out_img, curves, lanes, ploty = sliding_window(img_warp, draw_windows=False)\n",
        "\n",
        "        # Calculate curvature\n",
        "        curverad = get_curve(img, curves[0], curves[1])\n",
        "        lane_curve = np.mean([curverad[0], curverad[1]])\n",
        "\n",
        "        # Draw lanes\n",
        "        img_out = draw_lanes(img, curves[0], curves[1])\n",
        "\n",
        "        # Vehicle detection and distance calculation\n",
        "        vehicles = detect_vehicles(img_out)\n",
        "        img_out = draw_vehicle_detections(img_out, vehicles)\n",
        "\n",
        "        # Enhanced curve warning system\n",
        "        img_out = draw_enhanced_curve_warning(img_out, lane_curve)\n",
        "\n",
        "        # Get image dimensions\n",
        "        img_height, img_width = img_out.shape[:2]\n",
        "\n",
        "        # Create structured information panels\n",
        "        draw_info_panels(img_out, lane_curve, curverad[2], len(vehicles))\n",
        "\n",
        "        return img_out\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Pipeline error: {e}\")\n",
        "        return img\n",
        "\n",
        "def draw_info_panels(img, lane_curve, vehicle_offset, vehicle_count):\n",
        "    \"\"\"Draw well-structured information panels\"\"\"\n",
        "    img_height, img_width = img.shape[:2]\n",
        "\n",
        "    # Panel 1: Main Lane Information (Bottom Left)\n",
        "    panel1_x = 15\n",
        "    panel1_y = img_height - 140\n",
        "    panel1_width = 280\n",
        "    panel1_height = 125\n",
        "\n",
        "    # Create semi-transparent panel background\n",
        "    overlay = img.copy()\n",
        "    cv2.rectangle(overlay, (panel1_x, panel1_y), (panel1_x + panel1_width, panel1_y + panel1_height),\n",
        "                 (0, 0, 0), -1)\n",
        "    cv2.addWeighted(overlay, 0.7, img, 0.3, 0, img)\n",
        "\n",
        "    # Panel border\n",
        "    cv2.rectangle(img, (panel1_x, panel1_y), (panel1_x + panel1_width, panel1_y + panel1_height),\n",
        "                 (255, 255, 255), 2)\n",
        "\n",
        "    # Panel title\n",
        "    cv2.rectangle(img, (panel1_x, panel1_y), (panel1_x + panel1_width, panel1_y + 25),\n",
        "                 (50, 50, 200), -1)\n",
        "    cv2.putText(img, \"LANE INFORMATION\", (panel1_x + 10, panel1_y + 18),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    # Information text with proper spacing\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.55\n",
        "    font_thickness = 2\n",
        "    line_height = 22\n",
        "    text_color = (255, 255, 255)\n",
        "\n",
        "    # Lane curvature\n",
        "    cv2.putText(img, f\"Curvature:\", (panel1_x + 10, panel1_y + 45),\n",
        "               font, font_scale, text_color, font_thickness)\n",
        "    cv2.putText(img, f\"{lane_curve:.0f} m\", (panel1_x + 140, panel1_y + 45),\n",
        "               font, font_scale, (0, 255, 255), font_thickness)\n",
        "\n",
        "    # Vehicle offset\n",
        "    cv2.putText(img, f\"Vehicle Offset:\", (panel1_x + 10, panel1_y + 67),\n",
        "               font, font_scale, text_color, font_thickness)\n",
        "    offset_color = (0, 255, 0) if abs(vehicle_offset) < 0.1 else (0, 255, 255)\n",
        "    cv2.putText(img, f\"{vehicle_offset:.3f} m\", (panel1_x + 140, panel1_y + 67),\n",
        "               font, font_scale, offset_color, font_thickness)\n",
        "\n",
        "    # Vehicle count\n",
        "    cv2.putText(img, f\"Vehicles:\", (panel1_x + 10, panel1_y + 89),\n",
        "               font, font_scale, text_color, font_thickness)\n",
        "    count_color = (0, 255, 0) if vehicle_count == 0 else (0, 255, 255)\n",
        "    cv2.putText(img, f\"{vehicle_count}\", (panel1_x + 140, panel1_y + 89),\n",
        "               font, font_scale, count_color, font_thickness)\n",
        "\n",
        "    # Road status\n",
        "    curve_type = analyze_curve_severity(lane_curve)\n",
        "    road_status = curve_type.replace('_', ' ').title()\n",
        "    cv2.putText(img, f\"Road Status:\", (panel1_x + 10, panel1_y + 111),\n",
        "               font, font_scale, text_color, font_thickness)\n",
        "\n",
        "    # Color-code road status\n",
        "    if curve_type == \"SHARP_CURVE\":\n",
        "        status_color = (0, 0, 255)\n",
        "    elif curve_type == \"MODERATE_CURVE\":\n",
        "        status_color = (0, 165, 255)\n",
        "    elif curve_type == \"GENTLE_CURVE\":\n",
        "        status_color = (0, 255, 255)\n",
        "    else:\n",
        "        status_color = (0, 255, 0)\n",
        "\n",
        "    cv2.putText(img, road_status, (panel1_x + 140, panel1_y + 111),\n",
        "               font, font_scale, status_color, font_thickness)\n",
        "\n",
        "    # Panel 2: Speed & Safety Panel (Bottom Right)\n",
        "    panel2_width = 200\n",
        "    panel2_height = 80\n",
        "    panel2_x = img_width - panel2_width - 15\n",
        "    panel2_y = img_height - panel2_height - 15\n",
        "\n",
        "    # Create semi-transparent panel background\n",
        "    overlay2 = img.copy()\n",
        "    cv2.rectangle(overlay2, (panel2_x, panel2_y), (panel2_x + panel2_width, panel2_y + panel2_height),\n",
        "                 (0, 0, 0), -1)\n",
        "    cv2.addWeighted(overlay2, 0.7, img, 0.3, 0, img)\n",
        "\n",
        "    # Panel border\n",
        "    cv2.rectangle(img, (panel2_x, panel2_y), (panel2_x + panel2_width, panel2_y + panel2_height),\n",
        "                 (255, 255, 255), 2)\n",
        "\n",
        "    # Panel title\n",
        "    cv2.rectangle(img, (panel2_x, panel2_y), (panel2_x + panel2_width, panel2_y + 25),\n",
        "                 (0, 150, 0), -1)\n",
        "    cv2.putText(img, \"SAFETY STATUS\", (panel2_x + 10, panel2_y + 18),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    # Safety indicators\n",
        "    if lane_curve < 300:\n",
        "        safety_text = \"CAUTION\"\n",
        "        safety_color = (0, 165, 255)\n",
        "    elif vehicle_count > 0:\n",
        "        safety_text = \"MONITOR\"\n",
        "        safety_color = (0, 255, 255)\n",
        "    else:\n",
        "        safety_text = \"CLEAR\"\n",
        "        safety_color = (0, 255, 0)\n",
        "\n",
        "    cv2.putText(img, safety_text, (panel2_x + 10, panel2_y + 50),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, safety_color, 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "# Step 8: Main execution with better error handling\n",
        "def main():\n",
        "    \"\"\"Main function to run the enhanced lane detection\"\"\"\n",
        "    # Run calibration\n",
        "    print(\"Running camera calibration...\")\n",
        "    undistort_img()\n",
        "\n",
        "    # Test YOLO model with a sample\n",
        "    print(\"Testing YOLO model...\")\n",
        "    if yolo_model is not None:\n",
        "        try:\n",
        "            # Create a test image\n",
        "            test_img = np.ones((480, 640, 3), dtype=np.uint8) * 128\n",
        "            test_vehicles = detect_vehicles(test_img)\n",
        "            print(f\"YOLO model test: {len(test_vehicles)} vehicles detected in test image\")\n",
        "        except Exception as e:\n",
        "            print(f\"YOLO test failed: {e}\")\n",
        "    else:\n",
        "        print(\"Warning: YOLO model not loaded properly\")\n",
        "\n",
        "    # Check if video exists\n",
        "    video_path = 'project_video.mp4'\n",
        "    if not os.path.exists(video_path):\n",
        "        # Try alternative names\n",
        "        alternative_paths = ['project_video.mov', 'video.mp4', 'test_video.mp4', 'input.mp4']\n",
        "        found = False\n",
        "        for alt_path in alternative_paths:\n",
        "            if os.path.exists(alt_path):\n",
        "                video_path = alt_path\n",
        "                found = True\n",
        "                print(f\"Found video: {video_path}\")\n",
        "                break\n",
        "\n",
        "        if not found:\n",
        "            print(f\"Video file not found. Tried: {video_path}, {', '.join(alternative_paths)}\")\n",
        "            print(\"Please upload your video file and update the video_path variable.\")\n",
        "            return\n",
        "\n",
        "    # Process video\n",
        "    print(\"Processing video...\")\n",
        "    try:\n",
        "        myclip = VideoFileClip(video_path)\n",
        "        output_vid = 'enhanced_lane_detection_output.mp4'\n",
        "\n",
        "        print(f\"Video duration: {myclip.duration:.2f} seconds\")\n",
        "        print(f\"Video size: {myclip.size}\")\n",
        "        print(f\"Video FPS: {myclip.fps}\")\n",
        "\n",
        "        # Process with higher quality settings\n",
        "        clip = myclip.fl_image(vid_pipeline)\n",
        "        clip.write_videofile(output_vid,\n",
        "                           audio=False,\n",
        "                           codec='libx264',\n",
        "                           temp_audiofile='temp-audio.m4a',\n",
        "                           remove_temp=True,\n",
        "                           verbose=False,\n",
        "                           logger=None)\n",
        "\n",
        "        print(f\"Video processing complete! Output saved as: {output_vid}\")\n",
        "\n",
        "        # Display video\n",
        "        return HTML(f\"\"\"\n",
        "        <video width=\"1280\" height=\"720\" controls>\n",
        "          <source src=\"{output_vid}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "        \"\"\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Video processing error: {e}\")\n",
        "        print(\"Make sure your video file exists and is accessible.\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    result = main()\n",
        "    if result:\n",
        "        display(result)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/enhanced_lane_detection_output.mp4": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EQ6M61D9V8MS",
        "outputId": "6b9ea38c-61a5-4e68-b305-e790c01b4b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing YOLOv5...\n",
            "Ultralytics installed successfully\n",
            "Custom model not found, using YOLOv5s pretrained...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2025-7-26 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv5 loaded on cuda\n",
            "Running camera calibration...\n",
            "Camera calibration successful: 1.7494785357235567\n",
            "Testing YOLO model...\n",
            "YOLO model test: 0 vehicles detected in test image\n",
            "Processing video...\n",
            "Video duration: 50.40 seconds\n",
            "Video size: [1280, 720]\n",
            "Video FPS: 25.0\n",
            "Video processing complete! Output saved as: enhanced_lane_detection_output.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <video width=\"1280\" height=\"720\" controls>\n",
              "          <source src=\"enhanced_lane_detection_output.mp4\" type=\"video/mp4\">\n",
              "        </video>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}